(window.webpackJsonp=window.webpackJsonp||[]).push([[14],{439:function(r,e,a){r.exports=a.p+"assets/img/kafkaStruct.8af9f74b.png"},440:function(r,e,a){r.exports=a.p+"assets/img/kafkaFlow.201333cb.png"},489:function(r,e,a){"use strict";a.r(e);var t=a(33),o=Object(t.a)({},(function(){var r=this,e=r.$createElement,t=r._self._c||e;return t("ContentSlotsDistributor",{attrs:{"slot-key":r.$parent.slotKey}},[t("h1",{attrs:{id:"kafka初认识"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#kafka初认识"}},[r._v("#")]),r._v(" Kafka初认识")]),r._v(" "),t("blockquote",[t("p",[r._v("kafka是分布式，支持分区的(partition)，多副本的(replica)，基于zookeeper协调的分布式消息中间件。高吞吐量，低延迟，持久化，支持容错性。")])]),r._v(" "),t("h3",{attrs:{id:"kafka的设计思想"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#kafka的设计思想"}},[r._v("#")]),r._v(" kafka的设计思想")]),r._v(" "),t("ul",[t("li",[r._v("consumergroup：各个consumer可以组成一个group，每个消息只能被组中的一个consumer消费")]),r._v(" "),t("li",[r._v("消费状态：通过偏移量offset指向partition中下一个要被消费的消息位置，没有消费状态标志符")]),r._v(" "),t("li",[r._v("批量发送：Kafka支持以消息集合为单位进行批量发送，以提高push效率。")])]),r._v(" "),t("h3",{attrs:{id:"组成架构"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#组成架构"}},[r._v("#")]),r._v(" 组成架构")]),r._v(" "),t("p",[t("img",{attrs:{src:a(439),alt:""}})]),r._v(" "),t("ul",[t("li",[r._v("Producer：Producer即生产者，消息的产生者，是消息的入口。")]),r._v(" "),t("li",[r._v("Broker：Broker是kafka实例，每个服务器上有一个或多个kafka的实例")]),r._v(" "),t("li",[r._v("Topic：消息的主题，可以理解为消息的分类，kafka的数据就保存在topic。在每个broker上都可以创建多个topic。")]),r._v(" "),t("li",[r._v("Partition：Topic的分区，每个topic可以有多个分区，"),t("strong",[r._v("分区的作用是做负载")]),r._v("，提高kafka的吞吐量。同一个topic在不同的分区的数据是不重复的，partition的表现形式就是一个一个的文件夹！")]),r._v(" "),t("li",[r._v("Replication:每一个分区都有多个副本，副本的作用是做备胎。当主分区（Leader）故障的时候会选择一个备胎（Follower）上位，成为Leader。（默认副本最大10个，且不能大于broker数量），follower和leader绝对是在不同的机器")]),r._v(" "),t("li",[r._v("Message：每一条发送的消息主体")]),r._v(" "),t("li",[r._v("Zookeeper：kafka集群依赖zookeeper来保存集群的的元信息，来保证系统的可用性。")])]),r._v(" "),t("h3",{attrs:{id:"工作流程"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#工作流程"}},[r._v("#")]),r._v(" 工作流程")]),r._v(" "),t("p",[t("img",{attrs:{src:a(440),alt:""}}),r._v("\n消息写入leader后，follower是主动的去leader进行同步的！producer采用push模式将数据发布到broker，每条消息追加到分区中，顺序写入磁盘，所以保证同一分区内的数据是有序的。")]),r._v(" "),t("p",[r._v("生产端：")]),r._v(" "),t("ul",[t("li",[r._v("producer直接和partition leader交互获取元数据，发送消息")]),r._v(" "),t("li",[r._v("对应的partition leader收到消息先写入Page Cache，定期刷盘进行持久化（顺序写入磁盘）")]),r._v(" "),t("li",[r._v("Follower Partition 拉取 Leader Partition 的消息并保持同 Leader Partition 数据一致，同步成功后回复ACK确认消息")]),r._v(" "),t("li",[r._v("Leader Partition 会给 Producer 回复 ACK 确认消息")])]),r._v(" "),t("p",[r._v("消费端：")]),r._v(" "),t("ul",[t("li",[r._v("Consumer 拉取数据之前跟 Producer 发送数据一样, 需要通过订阅关系获取到集群元数据, 找到相关 Topic 对应的 Leader Partition 的元数据")]),r._v(" "),t("li",[r._v("然后 Consumer 通过 Pull 模式主动的去 Kafka 集群中拉取消息")]),r._v(" "),t("li",[r._v("拉取到消息后进行业务逻辑处理，待处理完成后，会进行 ACK 确认，即提交 Offset 消费位移进度记录。")]),r._v(" "),t("li",[r._v("最后 Offset 会被保存到 Kafka Broker 集群中的  __consumer_offsets 这个 Topic 中，且每个 Consumer 保存自己的 Offset 进度")])]),r._v(" "),t("p",[t("strong",[r._v("分区的目的")]),r._v("：")]),r._v(" "),t("ol",[t("li",[r._v("方便扩展：一个topic可以有多个partition,可以通过扩展机器应对数据量增加")]),r._v(" "),t("li",[r._v("提高并发：可以多个消费者同时消费数据，提高效率")])]),r._v(" "),t("h3",{attrs:{id:"消息丢失问题"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#消息丢失问题"}},[r._v("#")]),r._v(" 消息丢失问题")]),r._v(" "),t("blockquote",[t("p",[r._v("对于符合条件的消息（已提交且至少有一台机器存活），最大限度的持久化保证不丢失\n"),t("strong",[r._v("消息传递的语义")])])]),r._v(" "),t("ul",[t("li",[r._v("at mostly once：最多一次，有丢失消息的风险")]),r._v(" "),t("li",[r._v("at least once：至少一次，有重复消费的风险")]),r._v(" "),t("li",[r._v("exactly once：有且只有一次，精确处理")])]),r._v(" "),t("p",[t("strong",[r._v("三次消息传递的过程")])]),r._v(" "),t("ol",[t("li",[r._v("producer发送消息给broker端\n"),t("ul",[t("li",[r._v("为提升效率，减少IO操作，合并请求为一个RecordBatch，异步请求，所以失败的原因\n"),t("ul",[t("li",[r._v("网络异常抖动")]),r._v(" "),t("li",[r._v("消息太大超过broker承受范围导致拒收")])])]),r._v(" "),t("li",[r._v("消息大小进行处理")]),r._v(" "),t("li",[r._v("更换调用方式，弃用调用后即焚，使用带回调函数的方法发送消息")]),r._v(" "),t("li",[r._v("可以通过配置确认消息是否生产成功，request.require.ack\n"),t("ul",[t("li",[r._v("0 不需要ask")]),r._v(" "),t("li",[r._v("1 当leader partition接收成功时进行ack确认，确认后表示成功，保证了吞吐量，leader不能挂")]),r._v(" "),t("li",[r._v("-1 or all：所有leader和follower都接收成功时进行ack确认，最大限度不丢，但吞吐量低")])])])])]),r._v(" "),t("li",[r._v("broker端将消息同步并持久化数据\n"),t("ul",[t("li",[r._v("异步批量刷盘的策略，按照一定的消息量和时间间隔调用fsync命令强行刷盘，如果此时broker宕机，且选举一个落后的follower就会丢失数据\n"),t("ul",[t("li",[r._v("多 Partition （分区）多 Replica（副本）机制，太极端了")])])])])]),r._v(" "),t("li",[r._v("consumer从kafka broker拉取消息并消费\n"),t("ul",[t("li",[r._v("先提交offset，后处理消费消息，处理消费的时候宕机会导致消息丢失")]),r._v(" "),t("li",[r._v("先消费，再提交offset，提交时宕机会导致重复消费，可以通过自己实现逻辑幂等性")])])])]),r._v(" "),t("p",[t("RouterLink",{attrs:{to:"/docs/server/消息中间件.html"}},[r._v("与rocketMQ比较")])],1)])}),[],!1,null,null,null);e.default=o.exports}}]);